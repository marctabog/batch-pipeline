# Batch Pipeline Configuration

aws:
  bucket: buyer-finder
  region: eu-west-2
  s3_prefix_crawled: crawler-6k-results/processed
  s3_prefix_requests: crawler-6k-results/questions_gpt4omini_requests
  s3_prefix_responses: crawler-6k-results/questions_gpt4omini_responses
  s3_prefix_answers: crawler-6k-results/answers
  s3_prefix_tables: crawler-6k-results/tables

openai:
  model: gpt-5-mini
  batch_api: true
  temperature: 0.1
  max_tokens: 50000  # output limit

batch:
  batch_size: 1000  # requests per batch
  max_input_tokens: 200000  # truncate markdowns to this (NOTE: gpt-4o-mini has 128K total context window - adjust if needed)
  
processing:
  timeout_seconds: 300
  retry_attempts: 3
  
paths:
  prompts: prompts/
  inputs: inputs/
  requests: requests/
  responses: responses/
  tables: tables/
  manifests: manifests/
  logs: logs/
  tmp: tmp/

